# 统一张量编排的优化实现设计方案

## 目标与总览

在不破坏现有“自动缓存、结果追溯、并行执行、配置管理”四大特性的前提下，将框架从“标量节点编排”演进为“张量节点编排”。核心思路：

- **逻辑层（TensorNode）负责“定义与对齐”**，保证广播与维度语义正确。
- **物理层（Node）负责“执行与缓存”**，保持现有 DAG + 缓存与调度能力。
- **维度标记（Dim）作为对齐规则与广播触发器**，将标量与数组统一为同一套编排语义。

该方案强调：不改变现有 Node/Runtime 的“执行与缓存模型”，只在其上增加逻辑层，以最小改动获得最大一致性与可扩展性。

---

## 一、优化后核心对象职责划分

### 1. TensorNode（逻辑编排层）
**职责**：
- **定义层容器**：对用户暴露的主要操作对象。
- **承载逻辑依赖**：记录“函数 + 输入 TensorNode + 维度信息”形成宏观逻辑 DAG。
- **对齐与广播**：依据 Dim/shape 信息做对齐策略，决定最终 Node 网格结构。
- **生成脚本**：**只遍历 TensorNode 的逻辑引用**，输出简洁脚本（维持结果追溯的“高层语义”）。

**关键点**：
- TensorNode 本身不执行计算；只负责“规划执行”。
- TensorNode 需要保存 `logical_op`（函数对象）、`logical_inputs`（TensorNode/标量）、`dims`（显式维度）、`shape`、`alignment_plan`。

### 2. Node（物理执行层）
**职责**：
- **保持现有不可变原子语义**：存储函数与具体参数值，生成稳定哈希（沿用现有缓存逻辑）。
- **微观 DAG 执行单元**：所有并发调度和缓存命中以 Node 为粒度。
- **兼容标量**：标量任务即 `TensorNode(shape=())` 中的唯一 Node。

**关键点**：
- 继续使用当前 `Node` 的 hash 规则、依赖收集、脚本序列化能力。
- 不引入维度概念，Node 对广播“无感知”，只处理具体值。

### 3. Dim（维度标记/广播触发器）
**职责**：
- **维度语义注册**：对齐标签，作为广播的“规则输入”。
- **显式广播触发**：用户用 Dim 来声明可广播维度，避免隐式 shape 推断导致错误。

**关键点**：
- Dim 不参与计算，仅参与“对齐计划”的生成。
- Dim 的值可以来自 node.dim() 定义的函数，确保维度来源可配置、可缓存。

---

## 二、优化后运行逻辑（逻辑层→物理层）

### 1. 构建阶段（TensorNode → Node 网格）
1. **收集输入 TensorNode** 的 dims/shape。
2. **对齐规则生成**：
   - 以 Dim 作为坐标轴标签，参考 xarray 的“对齐优先”策略；
   - 若 Dim 不一致但可广播，则执行 broadcast；
   - 不可对齐则报错。
3. **广播结果**：
   - 生成统一 `shape`；
   - 为每个位置生成对应的 Node 参数快照；
   - 形成微观 DAG（Node 网格）。

### 2. 执行阶段（Node 微观 DAG）
- 与现有 Runtime 兼容：直接对 Node DAG 调度。
- 并行策略不变：对 Node 进行拓扑排序 + 并发执行。
- 缓存策略不变：仍以 Node hash 为 key，支持部分重算。

### 3. 追溯阶段（逻辑 DAG 还原）
- **脚本生成器只访问 TensorNode 逻辑 DAG**：
  - 不输出底层 Node 数组，只输出高层定义：
    - `Z = process(X, Y)`
- **底层 Node 的细节可选提供**：
  - 如需要 debug，可提供 `TensorNode.debug_script()` 生成微观脚本。

---

## 三、四大核心特性的保持与拓展

### 1. 自动缓存（保持 + 拓展）
**保持**：
- 仍以 Node hash 作为缓存 key（函数名 + 参数 + 依赖 Node 的 hash）。

**拓展**：
- TensorNode 的广播会拆分出多个 Node，因此**缓存粒度更细**。
- 支持“部分命中”：当广播维度某些元素已缓存时，仅重算缺失部分。

### 2. 结果追溯（保持 + 拓展）
**保持**：
- 现有 `Node.script` 仍可生成可执行脚本。

**拓展**：
- TensorNode 增加逻辑级脚本（宏观定义），例如：
  - `Z = process(X, Y)`
- 同时可选提供微观级脚本用于精确复现与调试。

### 3. 并行执行（保持 + 拓展）
**保持**：
- Runtime 仍按 Node DAG 调度，线程/进程并行机制不变。

**拓展**：
- 广播拆分后“节点更细”，可充分利用并发资源。
- 节点级流水线（上游某一元素完成即可触发下游对应元素），进一步提高吞吐。

### 4. 配置管理（保持 + 拓展）
**保持**：
- 现有 Config + YAML 机制继续生效。
- Node 参数仍可通过配置注入。

**拓展**：
- Dim 的生成函数可配置化，例如 `time_dim` 通过 YAML 构造。
- TensorNode 可直接从配置中生成维度数据，实现“配置即广播”。

---

## 四、最小化改动策略（兼容现有功能）

1. **Node/Runtime 核心不改**：保持执行、缓存、调度逻辑不动。
2. **新增 TensorNode 与 Dim 模块**：独立于现有 core/runtime。
3. **新增广播与对齐逻辑**：仅在 TensorNode 构建阶段执行。
4. **保留标量路径**：标量 Node 仍可作为 TensorNode(shape=())。
5. **逐步迁移**：先提供 TensorNode 的并行广播 API，不影响原 Node API。

---

## 五、预期收益

- **统一标量与数组逻辑**，减少重复实现。
- **广播带来天然并行**，提高吞吐与资源利用。
- **高层脚本更简洁**，便于审计与复现。
- **缓存粒度更细**，减少重复计算成本。

该方案在保留现有 Node/Runtime 运行模型的前提下，实现“逻辑编排层”升级，从而兼顾兼容性与扩展性。
